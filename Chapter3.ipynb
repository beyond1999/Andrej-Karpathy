{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef992704-0c37-495a-ad4b-f30e751e190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0ef02b6-7b6a-43f2-8240-765de358cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = torch.randn((27, 2))   # 形状 [27, 2]\n",
    "X = torch.tensor([[0, 1, 2],\n",
    "                  [3, 4, 5]])\n",
    "\n",
    "Y = C[X]                   # 问题的核心\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e593105-7811-4de4-a367-712662b08a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7229,  1.1623],\n",
       "        [-0.2811,  0.4724],\n",
       "        [-1.5925, -0.4540],\n",
       "        [ 0.8360, -0.0303],\n",
       "        [ 3.5172, -0.1093],\n",
       "        [-1.1626,  1.1527],\n",
       "        [-0.1892, -1.5313],\n",
       "        [ 2.3344, -0.6605],\n",
       "        [ 0.3138,  0.1057],\n",
       "        [ 0.2916,  1.1527],\n",
       "        [ 2.2592, -0.5524],\n",
       "        [ 0.2156, -0.8751],\n",
       "        [ 0.0073,  1.2154],\n",
       "        [ 1.1304, -0.6504],\n",
       "        [-1.0740, -0.1607],\n",
       "        [ 0.1354, -0.1082],\n",
       "        [ 0.6608, -0.9805],\n",
       "        [-1.4046,  1.7515],\n",
       "        [-1.7278, -2.7727],\n",
       "        [ 1.9631,  0.7612],\n",
       "        [-0.1070,  0.1592],\n",
       "        [-1.4153, -0.2194],\n",
       "        [ 0.2779, -1.1253],\n",
       "        [ 0.5158,  0.5184],\n",
       "        [-1.7501,  0.2225],\n",
       "        [-0.2218,  0.0555],\n",
       "        [ 1.0367,  1.5249]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bf127f-96c8-460f-8159-a6d9ec4ec702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6854e20b-bef6-4743-a94f-42950f747fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7229,  1.1623],\n",
       "         [-0.2811,  0.4724],\n",
       "         [-1.5925, -0.4540]],\n",
       "\n",
       "        [[ 0.8360, -0.0303],\n",
       "         [ 3.5172, -0.1093],\n",
       "         [-1.1626,  1.1527]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee19bb76-ebfc-4f43-a5c0-f2e6fbe0915a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ebf315-8af1-44b9-8f48-cba894a8f2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5172, -0.1093])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X][1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fcc5c-9ee0-4807-a61f-bf12594a8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52bb75f-74f8-4985-ada9-b4bbd813ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5172, -0.1093])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de52ced8-9cb3-4ed9-85a9-0fdb0c6185fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5172, -0.1093])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X[1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbe597cb-89e1-4288-b0ba-7bc9451a7e8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\"normal_kernel_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m C = torch.randn((\u001b[32m27\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: \"normal_kernel_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "X = torch.randn((32, 3), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "070de3c3-fc3f-472e-b039-3b708d0df105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0600a0cd-577d-4edf-b22c-e7c7dad524dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "# 用前三个预测下一个字符\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words:\n",
    "  \n",
    "  #print(w)\n",
    "  context = [0] * block_size\n",
    "  for ch in w + '.':\n",
    "    ix = stoi[ch]\n",
    "    X.append(context)\n",
    "    Y.append(ix)\n",
    "    #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "    context = context[1:] + [ix] # crop and append\n",
    "  \n",
    "X_hat = torch.tensor(X[:32])\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb5a1aec-2338-4b18-b48f-ddbba5ff0868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X_hat]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64d20598-1f80-4757-8b8c-7f09b2ad43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53a7680d-71c2-443a-b114-ac996d0be862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27]), torch.Size([27, 2]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).shape, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "798d583f-0869-43b0-9132-60702308aa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7867,  1.6594])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da090b75-a152-4d78-a2ca-67dbb051f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c981211b-ac38-48b5-ba41-6d0962239b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-0.6899, -2.6921],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-1.1801, -0.1231],\n",
       "         [-3.4855, -0.2580],\n",
       "         [-0.7431,  1.8755],\n",
       "         [-1.0747,  0.3682],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 1.0368, -1.0921],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-3.4855, -0.2580],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [-1.1801, -0.1231],\n",
       "         [ 1.2172, -0.5733],\n",
       "         [ 0.5785,  0.0120]]),\n",
       " tensor([[ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-0.6899, -2.6921],\n",
       "         [-0.6899, -2.6921],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-1.1801, -0.1231],\n",
       "         [-3.4855, -0.2580],\n",
       "         [-0.7431,  1.8755],\n",
       "         [-1.0747,  0.3682],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [-1.0747,  0.3682],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 1.0368, -1.0921],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-3.4855, -0.2580],\n",
       "         [-3.4855, -0.2580],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [-1.1801, -0.1231],\n",
       "         [ 1.2172, -0.5733],\n",
       "         [ 0.5785,  0.0120],\n",
       "         [-0.7431,  1.8755]]),\n",
       " tensor([[ 0.7816, -0.6910],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-0.6899, -2.6921],\n",
       "         [-0.6899, -2.6921],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-1.1801, -0.1231],\n",
       "         [-3.4855, -0.2580],\n",
       "         [-0.7431,  1.8755],\n",
       "         [-1.0747,  0.3682],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [-1.0747,  0.3682],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 1.0368, -1.0921],\n",
       "         [-0.7867,  1.6594],\n",
       "         [-3.4855, -0.2580],\n",
       "         [-3.4855, -0.2580],\n",
       "         [ 0.2183,  0.5439],\n",
       "         [ 0.7816, -0.6910],\n",
       "         [ 0.2381, -1.6071],\n",
       "         [-1.1801, -0.1231],\n",
       "         [ 1.2172, -0.5733],\n",
       "         [ 0.5785,  0.0120],\n",
       "         [-0.7431,  1.8755],\n",
       "         [ 0.2183,  0.5439]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef975168-3cf2-414a-a00b-d1b22d8fe53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6ff1379-efae-4bc1-8d9d-e0c8103348c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b68c647-f1c4-4d2d-86f4-ffceb466a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_update = torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03e80844-7175-4d59-8f4e-4a0dcd5d1ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4221, -4.0477, -4.3562,  ..., -2.6597, -0.4938, -2.2848],\n",
       "        [ 0.5022,  1.7120, -1.7554,  ..., -0.2904,  1.5057, -0.7614],\n",
       "        [-1.1815, -2.2726, -3.7528,  ..., -0.3477,  3.6135, -3.2374],\n",
       "        ...,\n",
       "        [-3.4768, -6.2050,  1.2300,  ...,  1.1881,  1.5280, -1.4609],\n",
       "        [ 1.6885,  2.0050, -1.6102,  ..., -0.4106,  1.7406, -1.4969],\n",
       "        [ 1.1064, -4.0104,  1.1602,  ...,  2.2070,  1.8790, -3.3571]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_update @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae47f7b8-e65b-42b0-ab24-65f2800713cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72219292-2134-4f67-8d62-001a21b4a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3, 3 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6e5cafe-2a34-4a9c-889f-0c77bceb1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gofor\\AppData\\Local\\Temp\\ipykernel_25388\\214256462.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5d80d81-0aa9-4dcd-9c3b-d96d18d46f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee3a7491-a627-4292-9e86-97281a3722b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, 6 ) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e34dbf25-b895-4772-b5f7-f5ecd3a474bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = emb.view(32, 6) @ W1 + b1\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2d04bb8-6fa0-42b9-b3a8-b2ede5976598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4221, -4.0477, -4.3562,  ..., -2.6597, -0.4938, -2.2848],\n",
       "        [ 0.5022,  1.7120, -1.7554,  ..., -0.2904,  1.5057, -0.7614],\n",
       "        [-1.1815, -2.2726, -3.7528,  ..., -0.3477,  3.6135, -3.2374],\n",
       "        ...,\n",
       "        [-3.4768, -6.2050,  1.2300,  ...,  1.1881,  1.5280, -1.4609],\n",
       "        [ 1.6885,  2.0050, -1.6102,  ..., -0.4106,  1.7406, -1.4969],\n",
       "        [ 1.1064, -4.0104,  1.1602,  ...,  2.2070,  1.8790, -3.3571]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3cb86df-e295-4d0e-ab95-703b328a4b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9979, -0.9994, -0.9997,  ..., -0.9903, -0.4572, -0.9795],\n",
       "        [ 0.4639,  0.9369, -0.9420,  ..., -0.2825,  0.9062, -0.6419],\n",
       "        [-0.8279, -0.9790, -0.9989,  ..., -0.3343,  0.9985, -0.9969],\n",
       "        ...,\n",
       "        [-0.9981, -1.0000,  0.8426,  ...,  0.8300,  0.9101, -0.8978],\n",
       "        [ 0.9340,  0.9644, -0.9232,  ..., -0.3890,  0.9403, -0.9046],\n",
       "        [ 0.8028, -0.9993,  0.8211,  ...,  0.9761,  0.9544, -0.9976]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(h)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f6715a6-e686-4cd2-b43d-7a1546c3a516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e0d98f8-a3aa-45c0-a674-4d0e6de76b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02937e50-034b-43f4-ac41-81cef3f39bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fe50d1c-00d3-44c4-9d45-edffd7305802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81e4152e-29cd-4eaa-a899-129bd4b71280",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1fe59b7-b16f-4e65-8452-267fadbe859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b48b6db-497d-4e12-827c-d83a51d82ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22c2b561-b1c9-495e-9c77-f8ad6758bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a220318-fadc-4676-8b19-0523d58d8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Y[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4642cd-1b18-4258-805b-0dc18388c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 是 [32, 3] 3代表的是blocksize=3 也就是3个字符作为上下文， 32是选的前32个单词作为输入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6436454-0d91-4edc-b6c2-cbf10481e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[torch.arange(32), Y_hat] #Y_hat是本该输出的那个字母的index（list）， 32个上下文，取出每一个对应Y_hat的位置的概率，这个概率越大说明预测结果越准确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07f6065c-4143-4235-a4c1-b7cae52634cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(32), Y_hat].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e276ebb-ec42-4dc4-b30c-b656da69ca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- now made respectable :) ----------------\n",
    "X_hat.shape, Y_hat.shape  # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "584121c4-762b-4cf7-9014-c7cce4cbcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C  = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49ef54a9-7a77-4ca1-970f-e76b676773a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)  # number of parameters in total\n",
    "# 3481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e73e8eb5-8bd9-4285-835a-7fde5563b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]                     # (32, 3, 2)\n",
    "h   = torch.tanh(emb.view(-1, 6) @ W1 + b1)   # (32, 100)\n",
    "logits = h @ W2 + b2           # (32, 27)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "loss = -prob[torch.arange(32), Y_hat].log().mean()\n",
    "loss\n",
    "# tensor(17.7692)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddad81c-8bff-42e2-9720-5bfdb9fb6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(logits, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "578f4efe-2d49-42a5-8db2-1c848ca82439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b781de2f-ace1-4795-85ff-332de137ee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.985849142074585\n",
      "3.6028308868408203\n",
      "3.262141704559326\n",
      "2.961380958557129\n",
      "2.6982972621917725\n",
      "2.469712972640991\n",
      "2.271660327911377\n",
      "2.1012840270996094\n",
      "1.9571772813796997\n",
      "1.8374855518341064\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    emb = C[X_hat]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y_hat)\n",
    "    print(loss.item())\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0af48-dbf1-4df4-aa1a-84f0b3e32816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpt)",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
